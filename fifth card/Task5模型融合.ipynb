{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task5模型融合.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOg+2NejZwgboG37YfVvnKy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jianmosier/Data-excavate/blob/master/fifth%20card/Task5%E6%A8%A1%E5%9E%8B%E8%9E%8D%E5%90%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCtzncF6X7dI",
        "colab_type": "text"
      },
      "source": [
        "#五、模型融合\n",
        "了解各种模型结果的融合方式"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzW2ScyCYOJm",
        "colab_type": "text"
      },
      "source": [
        "##5.1 模型融合目标\n",
        "\n",
        "\n",
        "*   对于多种调参完成的模型进行模型融合\n",
        "*   完成对于多种模型的融合，提交融合结果\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sbSEAANYoKT",
        "colab_type": "text"
      },
      "source": [
        "##5.2 内容介绍\n",
        "模型融合是比赛后期的一个重要环节，有如下类型方式\n",
        "\n",
        "1.   简单加权融合\n",
        "\n",
        " *   回归（分类概率）：算数平均融合，几何平均融合\n",
        " *   分类：投票（Voting）\n",
        "\n",
        " *   综合：排序融合，log融合\n",
        "2.   stacking/blending:\n",
        " *   构建多层模型，并利用预测结果再拟合预测。\n",
        "3.   boosting/bagging(在xgboost，Adaboost,GBDT中已经用到）：\n",
        " *   多树的提升方法\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrxMh8Vdjuvt",
        "colab_type": "text"
      },
      "source": [
        "##5.3 Stacking相关理论介绍\n",
        "1）什么是stacking\n",
        "简单来说stacking就是用初始训练数据学习出若干个基学习器后，将这几个学习器的预测结果作为新的训练集，来学习一个新的学习器。\n",
        "\n",
        "将个体学习器结合在一起的时候使用的方法叫做结合策略。对于分类问题，我们可以使用投票法来选择输出最多的类。对于回归问题，我们可以将分类器输出的结果求平均值。\n",
        "\n",
        "上面说的投票法和平均法都是很有效的结合策略，还有一种结合策略是使用另外一个机器学习算法来将个体学习器的结果结合在一起，这个方法就是stacking.\n",
        "\n",
        "在stacking中，我们把个体学习器叫做初级学习器，用于结合的学习器叫做次级学习器或元学习器，次级学习器用于训练的数据叫做次级训练集。次级训练集是在训练集上用初级学习器得到的。\n",
        "\n",
        "2)如何进行stacking\n",
        "算法示意图如下：![算法流程图](https://drive.google.com/uc?id=1vjir763sXbR67vnOz6GnH8Zcnm1mqSAi)\n",
        "*   过程1-3是训练出来个体学习器，也就是初级学习器\n",
        "\n",
        "*   过程5-9是使用训练出来的个体学习器来得预测的结果，这个预测的结果当做初级学习器的训练集\n",
        "*   过程11使用初级学习器预测的结果训练出次级学习器，得到我们最后训练的模型。\n",
        "\n",
        "3）Stacking的方法讲解\n",
        "首先，先从一种“不那么正确”\n",
        "但是容易懂的stacking方法讲起。\n",
        "stacking模型本质上是一种分层的结构，这里简单起见，只分析二级stacking。假设我们有2个基模型\n",
        "Model1_1、Model1_2和一个次级模型Model2\n",
        "\n",
        "**Step 1.**基模型Model1_1,对训练集train训练，然后用于预测train和test的标签列，分别是P1,T1\n",
        "Model1_1 模型训练：\n",
        "  ![公式1](https://drive.google.com/uc?id=13BLPic5eXgYEEtJCTg_9VgHtpYs1JMSK)\n",
        "\n",
        "训练后的模型Model1_1分别在train和test上预测，得到预测标签分别是P1,T1\n",
        "\n",
        "  ![公式2](https://drive.google.com/uc?id=1Gvw6BCFvvuTCN3_VC_b06DHiVvLoQTGV)\n",
        "\n",
        "  ![公式3](https://drive.google.com/uc?id=1_kEpxTqGmSH4dvhRFi2Gq4ewWCl-Ij_X)\n",
        "**Step 2.**基模型Model1_2,对训练集train训练，然后用于预测train和test的标签列，分别是P2,T2\n",
        "Model1_2模型训练：\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nmu-AsqVBLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 生成一些简单的样本数据，test_prei 代表第i个模型的预测值\n",
        "test_pre1 = [1.2, 3.2, 2.1, 6.2]\n",
        "test_pre2 = [0.9, 3.1, 2.0, 5.9]\n",
        "test_pre3 = [1.1, 2.9, 2.2, 6.0]\n",
        "\n",
        "# y_test_true 代表第模型的真实值\n",
        "y_test_true = [1, 3, 2, 6] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzqqK23aVXw6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "## 定义结果的加权平均函数\n",
        "def Weighted_method(test_pre1,test_pre2,test_pre3,w=[1/3,1/3,1/3]):\n",
        "    Weighted_result = w[0]*pd.Series(test_pre1)+w[1]*pd.Series(test_pre2)+w[2]*pd.Series(test_pre3)\n",
        "    return Weighted_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCSxuyouVaVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "# 各模型的预测结果计算MAE\n",
        "print('Pred1 MAE:',metrics.mean_absolute_error(y_test_true, test_pre1))\n",
        "print('Pred2 MAE:',metrics.mean_absolute_error(y_test_true, test_pre2))\n",
        "print('Pred3 MAE:',metrics.mean_absolute_error(y_test_true, test_pre3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoD5S-8IVdW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 根据加权计算MAE\n",
        "w = [0.3,0.4,0.3] # 定义比重权值\n",
        "Weighted_pre = Weighted_method(test_pre1,test_pre2,test_pre3,w)\n",
        "print('Weighted_pre MAE:',metrics.mean_absolute_error(y_test_true, Weighted_pre))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdLs4GyAVgUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 定义结果的加权平均函数\n",
        "def Mean_method(test_pre1,test_pre2,test_pre3):\n",
        "    Mean_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).mean(axis=1)\n",
        "    return Mean_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcjEDci3ViVe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Mean_pre = Mean_method(test_pre1,test_pre2,test_pre3)\n",
        "print('Mean_pre MAE:',metrics.mean_absolute_error(y_test_true, Mean_pre))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej_Rn3YOVk9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 定义结果的加权平均函数\n",
        "def Median_method(test_pre1,test_pre2,test_pre3):\n",
        "    Median_result = pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).median(axis=1)\n",
        "    return Median_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n9ohgzJVpUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Median_pre = Median_method(test_pre1,test_pre2,test_pre3)\n",
        "print('Median_pre MAE:',metrics.mean_absolute_error(y_test_true, Median_pre))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ugbAoL9Vrw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "def Stacking_method(train_reg1,train_reg2,train_reg3,y_train_true,test_pre1,test_pre2,test_pre3,model_L2= linear_model.LinearRegression()):\n",
        "    model_L2.fit(pd.concat([pd.Series(train_reg1),pd.Series(train_reg2),pd.Series(train_reg3)],axis=1).values,y_train_true)\n",
        "    Stacking_result = model_L2.predict(pd.concat([pd.Series(test_pre1),pd.Series(test_pre2),pd.Series(test_pre3)],axis=1).values)\n",
        "    return Stacking_result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLNPWMu-Vumx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 生成一些简单的样本数据，test_prei 代表第i个模型的预测值\n",
        "train_reg1 = [3.2, 8.2, 9.1, 5.2]\n",
        "train_reg2 = [2.9, 8.1, 9.0, 4.9]\n",
        "train_reg3 = [3.1, 7.9, 9.2, 5.0]\n",
        "# y_test_true 代表第模型的真实值\n",
        "y_train_true = [3, 8, 9, 5] \n",
        "\n",
        "test_pre1 = [1.2, 3.2, 2.1, 6.2]\n",
        "test_pre2 = [0.9, 3.1, 2.0, 5.9]\n",
        "test_pre3 = [1.1, 2.9, 2.2, 6.0]\n",
        "\n",
        "# y_test_true 代表第模型的真实值\n",
        "y_test_true = [1, 3, 2, 6] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it15SczkV2QJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_L2= linear_model.LinearRegression()\n",
        "Stacking_pre = Stacking_method(train_reg1,train_reg2,train_reg3,y_train_true,\n",
        "                               test_pre1,test_pre2,test_pre3,model_L2)\n",
        "print('Stacking_pre MAE:',metrics.mean_absolute_error(y_test_true, Stacking_pre))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-IrYLTlV4YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb5JwNq4WEVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "硬投票：对多个模型直接进行投票，不区分模型结果的相对重要度，最终投票数最多的类为最终被预测的类。\n",
        "'''\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
        "\n",
        "clf1 = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=3, min_child_weight=2, subsample=0.7,\n",
        "                     colsample_bytree=0.6, objective='binary:logistic')\n",
        "clf2 = RandomForestClassifier(n_estimators=50, max_depth=1, min_samples_split=4,\n",
        "                              min_samples_leaf=63,oob_score=True)\n",
        "clf3 = SVC(C=0.1)\n",
        "\n",
        "# 硬投票\n",
        "eclf = VotingClassifier(estimators=[('xgb', clf1), ('rf', clf2), ('svc', clf3)], voting='hard')\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):\n",
        "    scores = cross_val_score(clf, x, y, cv=5, scoring='accuracy')\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyDdMrjUWIFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "软投票：和硬投票原理相同，增加了设置权重的功能，可以为不同模型设置不同权重，进而区别模型不同的重要度。\n",
        "'''\n",
        "x=iris.data\n",
        "y=iris.target\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3)\n",
        "\n",
        "clf1 = XGBClassifier(learning_rate=0.1, n_estimators=150, max_depth=3, min_child_weight=2, subsample=0.8,\n",
        "                     colsample_bytree=0.8, objective='binary:logistic')\n",
        "clf2 = RandomForestClassifier(n_estimators=50, max_depth=1, min_samples_split=4,\n",
        "                              min_samples_leaf=63,oob_score=True)\n",
        "clf3 = SVC(C=0.1, probability=True)\n",
        "\n",
        "# 软投票\n",
        "eclf = VotingClassifier(estimators=[('xgb', clf1), ('rf', clf2), ('svc', clf3)], voting='soft', weights=[2, 1, 1])\n",
        "clf1.fit(x_train, y_train)\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['XGBBoosting', 'Random Forest', 'SVM', 'Ensemble']):\n",
        "    scores = cross_val_score(clf, x, y, cv=5, scoring='accuracy')\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd38_29oWQt4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "5-Fold Stacking\n",
        "'''\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier,GradientBoostingClassifier\n",
        "import pandas as pd\n",
        "#创建训练的数据集\n",
        "data_0 = iris.data\n",
        "data = data_0[:100,:]\n",
        "\n",
        "target_0 = iris.target\n",
        "target = target_0[:100]\n",
        "\n",
        "#模型融合中使用到的各个单模型\n",
        "clfs = [LogisticRegression(solver='lbfgs'),\n",
        "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
        "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]\n",
        " \n",
        "#切分一部分数据作为测试集\n",
        "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)\n",
        "\n",
        "dataset_blend_train = np.zeros((X.shape[0], len(clfs)))\n",
        "dataset_blend_test = np.zeros((X_predict.shape[0], len(clfs)))\n",
        "\n",
        "#5折stacking\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits)\n",
        "skf = skf.split(X, y)\n",
        "\n",
        "for j, clf in enumerate(clfs):\n",
        "    #依次训练各个单模型\n",
        "    dataset_blend_test_j = np.zeros((X_predict.shape[0], 5))\n",
        "    for i, (train, test) in enumerate(skf):\n",
        "        #5-Fold交叉训练，使用第i个部分作为预测，剩余的部分来训练模型，获得其预测的输出作为第i部分的新特征。\n",
        "        X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_submission = clf.predict_proba(X_test)[:, 1]\n",
        "        dataset_blend_train[test, j] = y_submission\n",
        "        dataset_blend_test_j[:, i] = clf.predict_proba(X_predict)[:, 1]\n",
        "    #对于测试集，直接用这k个模型的预测值均值作为新的特征。\n",
        "    dataset_blend_test[:, j] = dataset_blend_test_j.mean(1)\n",
        "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_blend_test[:, j]))\n",
        "\n",
        "clf = LogisticRegression(solver='lbfgs')\n",
        "clf.fit(dataset_blend_train, y)\n",
        "y_submission = clf.predict_proba(dataset_blend_test)[:, 1]\n",
        "\n",
        "print(\"Val auc Score of Stacking: %f\" % (roc_auc_score(y_predict, y_submission)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzp9L5NZWV8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Blending\n",
        "'''\n",
        " \n",
        "#创建训练的数据集\n",
        "#创建训练的数据集\n",
        "data_0 = iris.data\n",
        "data = data_0[:100,:]\n",
        "\n",
        "target_0 = iris.target\n",
        "target = target_0[:100]\n",
        " \n",
        "#模型融合中使用到的各个单模型\n",
        "clfs = [LogisticRegression(solver='lbfgs'),\n",
        "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        #ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
        "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]\n",
        " \n",
        "#切分一部分数据作为测试集\n",
        "X, X_predict, y, y_predict = train_test_split(data, target, test_size=0.3, random_state=2020)\n",
        "\n",
        "#切分训练数据集为d1,d2两部分\n",
        "X_d1, X_d2, y_d1, y_d2 = train_test_split(X, y, test_size=0.5, random_state=2020)\n",
        "dataset_d1 = np.zeros((X_d2.shape[0], len(clfs)))\n",
        "dataset_d2 = np.zeros((X_predict.shape[0], len(clfs)))\n",
        " \n",
        "for j, clf in enumerate(clfs):\n",
        "    #依次训练各个单模型\n",
        "    clf.fit(X_d1, y_d1)\n",
        "    y_submission = clf.predict_proba(X_d2)[:, 1]\n",
        "    dataset_d1[:, j] = y_submission\n",
        "    #对于测试集，直接用这k个模型的预测值作为新的特征。\n",
        "    dataset_d2[:, j] = clf.predict_proba(X_predict)[:, 1]\n",
        "    print(\"val auc Score: %f\" % roc_auc_score(y_predict, dataset_d2[:, j]))\n",
        "\n",
        "#融合使用的模型\n",
        "clf = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)\n",
        "clf.fit(dataset_d1, y_d2)\n",
        "y_submission = clf.predict_proba(dataset_d2)[:, 1]\n",
        "print(\"Val auc Score of Blending: %f\" % (roc_auc_score(y_predict, y_submission)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fobch1nLWXbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mlxtend\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import itertools\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from mlxtend.classifier import StackingClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from mlxtend.plotting import plot_learning_curves\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "# 以python自带的鸢尾花数据集为例\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data[:, 1:3], iris.target\n",
        "\n",
        "clf1 = KNeighborsClassifier(n_neighbors=1)\n",
        "clf2 = RandomForestClassifier(random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "lr = LogisticRegression()\n",
        "sclf = StackingClassifier(classifiers=[clf1, clf2, clf3], \n",
        "                          meta_classifier=lr)\n",
        "\n",
        "label = ['KNN', 'Random Forest', 'Naive Bayes', 'Stacking Classifier']\n",
        "clf_list = [clf1, clf2, clf3, sclf]\n",
        "\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "gs = gridspec.GridSpec(2, 2)\n",
        "grid = itertools.product([0,1],repeat=2)\n",
        "\n",
        "clf_cv_mean = []\n",
        "clf_cv_std = []\n",
        "for clf, label, grd in zip(clf_list, label, grid):\n",
        "        \n",
        "    scores = cross_val_score(clf, X, y, cv=3, scoring='accuracy')\n",
        "    print(\"Accuracy: %.2f (+/- %.2f) [%s]\" %(scores.mean(), scores.std(), label))\n",
        "    clf_cv_mean.append(scores.mean())\n",
        "    clf_cv_std.append(scores.std())\n",
        "        \n",
        "    clf.fit(X, y)\n",
        "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
        "    fig = plot_decision_regions(X=X, y=y, clf=clf)\n",
        "    plt.title(label)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE1ApwAfWe5p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Ensemble_add_feature(train,test,target,clfs):\n",
        "    \n",
        "    # n_flods = 5\n",
        "    # skf = list(StratifiedKFold(y, n_folds=n_flods))\n",
        "\n",
        "    train_ = np.zeros((train.shape[0],len(clfs*2)))\n",
        "    test_ = np.zeros((test.shape[0],len(clfs*2)))\n",
        "\n",
        "    for j,clf in enumerate(clfs):\n",
        "        '''依次训练各个单模型'''\n",
        "        # print(j, clf)\n",
        "        '''使用第1个部分作为预测，第2部分来训练模型，获得其预测的输出作为第2部分的新特征。'''\n",
        "        # X_train, y_train, X_test, y_test = X[train], y[train], X[test], y[test]\n",
        "\n",
        "        clf.fit(train,target)\n",
        "        y_train = clf.predict(train)\n",
        "        y_test = clf.predict(test)\n",
        "\n",
        "        ## 新特征生成\n",
        "        train_[:,j*2] = y_train**2\n",
        "        test_[:,j*2] = y_test**2\n",
        "        train_[:, j+1] = np.exp(y_train)\n",
        "        test_[:, j+1] = np.exp(y_test)\n",
        "        # print(\"val auc Score: %f\" % r2_score(y_predict, dataset_d2[:, j]))\n",
        "        print('Method ',j)\n",
        "    \n",
        "    train_ = pd.DataFrame(train_)\n",
        "    test_ = pd.DataFrame(test_)\n",
        "    return train_,test_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RItxDiu9Wj0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf = LogisticRegression()\n",
        "\n",
        "data_0 = iris.data\n",
        "data = data_0[:100,:]\n",
        "\n",
        "target_0 = iris.target\n",
        "target = target_0[:100]\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(data,target,test_size=0.3)\n",
        "x_train = pd.DataFrame(x_train) ; x_test = pd.DataFrame(x_test)\n",
        "\n",
        "#模型融合中使用到的各个单模型\n",
        "clfs = [LogisticRegression(),\n",
        "        RandomForestClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='gini'),\n",
        "        ExtraTreesClassifier(n_estimators=5, n_jobs=-1, criterion='entropy'),\n",
        "        GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=5)]\n",
        "\n",
        "New_train,New_test = Ensemble_add_feature(x_train,x_test,y_train,clfs)\n",
        "\n",
        "clf = LogisticRegression()\n",
        "# clf = GradientBoostingClassifier(learning_rate=0.02, subsample=0.5, max_depth=6, n_estimators=30)\n",
        "clf.fit(New_train, y_train)\n",
        "y_emb = clf.predict_proba(New_test)[:, 1]\n",
        "\n",
        "print(\"Val auc Score of stacking: %f\" % (roc_auc_score(y_test, y_emb)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TyjzBK7WrKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "import itertools\n",
        "import matplotlib.gridspec as gridspec\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# from mlxtend.classifier import StackingClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split\n",
        "# from mlxtend.plotting import plot_learning_curves\n",
        "# from mlxtend.plotting import plot_decision_regions\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.decomposition import PCA,FastICA,FactorAnalysis,SparsePCA\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOEzEgXZWtla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 数据读取\n",
        "Train_data = pd.read_csv('datalab/231784/used_car_train_20200313.csv', sep=' ')\n",
        "TestA_data = pd.read_csv('datalab/231784/used_car_testA_20200313.csv', sep=' ')\n",
        "\n",
        "print(Train_data.shape)\n",
        "print(TestA_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPhsfsCsWv9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Train_data.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hZmx36_Wy-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numerical_cols = Train_data.select_dtypes(exclude = 'object').columns\n",
        "print(numerical_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0O1KOwmW1uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_cols = [col for col in numerical_cols if col not in ['SaleID','name','regDate','price']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujntYzsJW423",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_data = Train_data[feature_cols]\n",
        "Y_data = Train_data['price']\n",
        "\n",
        "X_test  = TestA_data[feature_cols]\n",
        "\n",
        "print('X train shape:',X_data.shape)\n",
        "print('X test shape:',X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU-fL5bLW_KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Sta_inf(data):\n",
        "    print('_min',np.min(data))\n",
        "    print('_max:',np.max(data))\n",
        "    print('_mean',np.mean(data))\n",
        "    print('_ptp',np.ptp(data))\n",
        "    print('_std',np.std(data))\n",
        "    print('_var',np.var(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utFKsCF8XCeH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Sta of label:')\n",
        "Sta_inf(Y_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g36ikr6NXE7z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_data = X_data.fillna(-1)\n",
        "X_test = X_test.fillna(-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oSd7CN3XJqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model_lr(x_train,y_train):\n",
        "    reg_model = linear_model.LinearRegression()\n",
        "    reg_model.fit(x_train,y_train)\n",
        "    return reg_model\n",
        "\n",
        "def build_model_ridge(x_train,y_train):\n",
        "    reg_model = linear_model.Ridge(alpha=0.8)#alphas=range(1,100,5)\n",
        "    reg_model.fit(x_train,y_train)\n",
        "    return reg_model\n",
        "\n",
        "def build_model_lasso(x_train,y_train):\n",
        "    reg_model = linear_model.LassoCV()\n",
        "    reg_model.fit(x_train,y_train)\n",
        "    return reg_model\n",
        "\n",
        "def build_model_gbdt(x_train,y_train):\n",
        "    estimator =GradientBoostingRegressor(loss='ls',subsample= 0.85,max_depth= 5,n_estimators = 100)\n",
        "    param_grid = { \n",
        "            'learning_rate': [0.05,0.08,0.1,0.2],\n",
        "            }\n",
        "    gbdt = GridSearchCV(estimator, param_grid,cv=3)\n",
        "    gbdt.fit(x_train,y_train)\n",
        "    print(gbdt.best_params_)\n",
        "    # print(gbdt.best_estimator_ )\n",
        "    return gbdt\n",
        "\n",
        "def build_model_xgb(x_train,y_train):\n",
        "    model = xgb.XGBRegressor(n_estimators=120, learning_rate=0.08, gamma=0, subsample=0.8,\\\n",
        "        colsample_bytree=0.9, max_depth=5) #, objective ='reg:squarederror'\n",
        "    model.fit(x_train, y_train)\n",
        "    return model\n",
        "\n",
        "def build_model_lgb(x_train,y_train):\n",
        "    estimator = lgb.LGBMRegressor(num_leaves=63,n_estimators = 100)\n",
        "    param_grid = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "    }\n",
        "    gbm = GridSearchCV(estimator, param_grid)\n",
        "    gbm.fit(x_train, y_train)\n",
        "    return gbm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jie0dGuwXNcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## xgb\n",
        "xgr = xgb.XGBRegressor(n_estimators=120, learning_rate=0.1, subsample=0.8,\\\n",
        "        colsample_bytree=0.9, max_depth=7) # ,objective ='reg:squarederror'\n",
        "\n",
        "scores_train = []\n",
        "scores = []\n",
        "\n",
        "## 5折交叉验证方式\n",
        "sk=StratifiedKFold(n_splits=5,shuffle=True,random_state=0)\n",
        "for train_ind,val_ind in sk.split(X_data,Y_data):\n",
        "    \n",
        "    train_x=X_data.iloc[train_ind].values\n",
        "    train_y=Y_data.iloc[train_ind]\n",
        "    val_x=X_data.iloc[val_ind].values\n",
        "    val_y=Y_data.iloc[val_ind]\n",
        "    \n",
        "    xgr.fit(train_x,train_y)\n",
        "    pred_train_xgb=xgr.predict(train_x)\n",
        "    pred_xgb=xgr.predict(val_x)\n",
        "    \n",
        "    score_train = mean_absolute_error(train_y,pred_train_xgb)\n",
        "    scores_train.append(score_train)\n",
        "    score = mean_absolute_error(val_y,pred_xgb)\n",
        "    scores.append(score)\n",
        "\n",
        "print('Train mae:',np.mean(score_train))\n",
        "print('Val mae',np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ginVo9feXQGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Split data with val\n",
        "x_train,x_val,y_train,y_val = train_test_split(X_data,Y_data,test_size=0.3)\n",
        "\n",
        "## Train and Predict\n",
        "print('Predict LR...')\n",
        "model_lr = build_model_lr(x_train,y_train)\n",
        "val_lr = model_lr.predict(x_val)\n",
        "subA_lr = model_lr.predict(X_test)\n",
        "\n",
        "print('Predict Ridge...')\n",
        "model_ridge = build_model_ridge(x_train,y_train)\n",
        "val_ridge = model_ridge.predict(x_val)\n",
        "subA_ridge = model_ridge.predict(X_test)\n",
        "\n",
        "print('Predict Lasso...')\n",
        "model_lasso = build_model_lasso(x_train,y_train)\n",
        "val_lasso = model_lasso.predict(x_val)\n",
        "subA_lasso = model_lasso.predict(X_test)\n",
        "\n",
        "print('Predict GBDT...')\n",
        "model_gbdt = build_model_gbdt(x_train,y_train)\n",
        "val_gbdt = model_gbdt.predict(x_val)\n",
        "subA_gbdt = model_gbdt.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcHLYgRkXWVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('predict XGB...')\n",
        "model_xgb = build_model_xgb(x_train,y_train)\n",
        "val_xgb = model_xgb.predict(x_val)\n",
        "subA_xgb = model_xgb.predict(X_test)\n",
        "\n",
        "print('predict lgb...')\n",
        "model_lgb = build_model_lgb(x_train,y_train)\n",
        "val_lgb = model_lgb.predict(x_val)\n",
        "subA_lgb = model_lgb.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddbipguKXZB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Sta inf of lgb:')\n",
        "Sta_inf(subA_lgb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reRXTdjkXccm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Weighted_method(test_pre1,test_pre2,test_pre3,w=[1/3,1/3,1/3]):\n",
        "    Weighted_result = w[0]*pd.Series(test_pre1)+w[1]*pd.Series(test_pre2)+w[2]*pd.Series(test_pre3)\n",
        "    return Weighted_result\n",
        "\n",
        "## Init the Weight\n",
        "w = [0.3,0.4,0.3]\n",
        "\n",
        "## 测试验证集准确度\n",
        "val_pre = Weighted_method(val_lgb,val_xgb,val_gbdt,w)\n",
        "MAE_Weighted = mean_absolute_error(y_val,val_pre)\n",
        "print('MAE of Weighted of val:',MAE_Weighted)\n",
        "\n",
        "## 预测数据部分\n",
        "subA = Weighted_method(subA_lgb,subA_xgb,subA_gbdt,w)\n",
        "print('Sta inf:')\n",
        "Sta_inf(subA)\n",
        "## 生成提交文件\n",
        "sub = pd.DataFrame()\n",
        "sub['SaleID'] = X_test.index\n",
        "sub['price'] = subA\n",
        "sub.to_csv('./sub_Weighted.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9wBnBYoXgJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 与简单的LR（线性回归）进行对比\n",
        "val_lr_pred = model_lr.predict(x_val)\n",
        "MAE_lr = mean_absolute_error(y_val,val_lr_pred)\n",
        "print('MAE of lr:',MAE_lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNvjw8LwXkoy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Starking\n",
        "\n",
        "## 第一层\n",
        "train_lgb_pred = model_lgb.predict(x_train)\n",
        "train_xgb_pred = model_xgb.predict(x_train)\n",
        "train_gbdt_pred = model_gbdt.predict(x_train)\n",
        "\n",
        "Strak_X_train = pd.DataFrame()\n",
        "Strak_X_train['Method_1'] = train_lgb_pred\n",
        "Strak_X_train['Method_2'] = train_xgb_pred\n",
        "Strak_X_train['Method_3'] = train_gbdt_pred\n",
        "\n",
        "Strak_X_val = pd.DataFrame()\n",
        "Strak_X_val['Method_1'] = val_lgb\n",
        "Strak_X_val['Method_2'] = val_xgb\n",
        "Strak_X_val['Method_3'] = val_gbdt\n",
        "\n",
        "Strak_X_test = pd.DataFrame()\n",
        "Strak_X_test['Method_1'] = subA_lgb\n",
        "Strak_X_test['Method_2'] = subA_xgb\n",
        "Strak_X_test['Method_3'] = subA_gbdt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXM782WKXm7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Strak_X_test.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW-UD092XreG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## level2-method \n",
        "model_lr_Stacking = build_model_lr(Strak_X_train,y_train)\n",
        "## 训练集\n",
        "train_pre_Stacking = model_lr_Stacking.predict(Strak_X_train)\n",
        "print('MAE of Stacking-LR:',mean_absolute_error(y_train,train_pre_Stacking))\n",
        "\n",
        "## 验证集\n",
        "val_pre_Stacking = model_lr_Stacking.predict(Strak_X_val)\n",
        "print('MAE of Stacking-LR:',mean_absolute_error(y_val,val_pre_Stacking))\n",
        "\n",
        "## 预测集\n",
        "print('Predict Stacking-LR...')\n",
        "subA_Stacking = model_lr_Stacking.predict(Strak_X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji06rYeaXuTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subA_Stacking[subA_Stacking<10]=10  ## 去除过小的预测值\n",
        "\n",
        "sub = pd.DataFrame()\n",
        "sub['SaleID'] = TestA_data.SaleID\n",
        "sub['price'] = subA_Stacking\n",
        "sub.to_csv('./sub_Stacking.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7c-HUdeXw2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Sta inf:')\n",
        "Sta_inf(subA_Stacking)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}